import os
from pathlib import Path
import pickle
import numpy as np
import pandas as pd
import streamlit as st

# -----------------------------
# 0) TensorFlow ê°€ë“œ (Cloudì—ì„œ ì›ì¸ í‘œì‹œ)
# -----------------------------
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
except Exception as e:
    st.error(
        "TensorFlowë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
        "requirements.txtì™€ runtime.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.\n\n"
        f"[ì›ì¸] {e}"
    )
    st.stop()

st.set_page_config(page_title="MovieLens AutoInt Recommender", layout="wide")

# -----------------------------
# 1) ê²½ë¡œ/í•„ìˆ˜ íŒŒì¼ ì²´í¬
# -----------------------------
DATA_DIR = Path("data/ml-1m")
ART_DIR  = Path("artifacts")
MODEL_W  = Path("model/autoInt_model.weights.h5")

required_files = [
    DATA_DIR / "users.dat",
    DATA_DIR / "movies.dat",
    DATA_DIR / "ratings.dat",
    ART_DIR / "field_dims.npy",
    ART_DIR / "label_encoders.pkl",
    MODEL_W,
]

missing = [str(p) for p in required_files if not p.exists()]
if missing:
    st.error(
        "í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ íŒŒì¼ì„ ë ˆí¬ì§€í† ë¦¬ì— í¬í•¨í•˜ì„¸ìš”.\n\n"
        + "\n".join(missing)
    )
    st.stop()

# -----------------------------
# 2) ê²½ëŸ‰ ë¡œë”© (ìºì‹œ)
# -----------------------------
@st.cache_data(show_spinner=False)
def load_small_tables():
    users = pd.read_csv(
        DATA_DIR / "users.dat", sep="::", engine="python",
        names=["user_id","gender","age","occupation","zip"]
    )
    movies = pd.read_csv(
        DATA_DIR / "movies.dat", sep="::", engine="python",
        names=["movie_id","title","genres"]
    )
    ratings = pd.read_csv(
        DATA_DIR / "ratings.dat", sep="::", engine="python",
        names=["user_id","movie_id","rating","timestamp"]
    )
    ratings["label"] = (ratings["rating"] >= 4).astype(int)
    ratings["ts"] = pd.to_datetime(ratings["timestamp"], unit="s")
    ratings["rating_year"]  = ratings["ts"].dt.year
    ratings["rating_month"] = ratings["ts"].dt.month
    movies["main_genre"] = movies["genres"].str.split("|").str[0]
    return users, movies, ratings

@st.cache_resource(show_spinner=False)
def load_artifacts_and_model():
    # label encoders / field dims
    field_dims = np.load(ART_DIR / "field_dims.npy")
    with open(ART_DIR / "label_encoders.pkl", "rb") as f:
        enc_obj = pickle.load(f)
    cat_cols        = enc_obj["cat_cols"]
    label_encoders  = enc_obj["label_encoders"]

    # ===== AutoInt ëª¨ë¸ êµ¬ì¡° (í•™ìŠµê³¼ ë™ì¼í•´ì•¼ í•¨) =====
    num_fields  = len(cat_cols)
    embed_dim   = 32
    num_heads   = 4
    attn_layers = 2
    dropout_rate = 0.2
    mlp_units   = [128, 64]

    inp = keras.Input(shape=(num_fields,), dtype="int32")
    embeds = []
    for i, dim in enumerate(field_dims):
        vi = layers.Lambda(lambda x: tf.gather(x, indices=i, axis=1))(inp)
        vi = layers.Reshape((1,))(vi)
        ei = layers.Embedding(input_dim=int(dim), output_dim=embed_dim)(vi)
        embeds.append(ei)
    E = layers.Concatenate(axis=1)(embeds)

    x = E
    for _ in range(attn_layers):
        attn_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)(x, x)
        x = layers.Add()([x, attn_out])
        x = layers.LayerNormalization()(x)

    x = layers.GlobalAveragePooling1D()(x)
    for u in mlp_units:
        x = layers.Dense(u, activation="relu")(x)
        x = layers.Dropout(dropout_rate)(x)
    out = layers.Dense(1, activation="sigmoid")(x)

    model = keras.Model(inputs=inp, outputs=out)
    model.compile(optimizer="adam", loss="binary_crossentropy")
    # ë”ë¯¸ í˜¸ì¶œë¡œ build
    _ = model.predict(np.zeros((1, num_fields), dtype=np.int32), verbose=0)
    # ê°€ì¤‘ì¹˜ ë¡œë“œ (.weights.h5 í•„ìˆ˜)
    model.load_weights(str(MODEL_W))
    return cat_cols, label_encoders, field_dims, model

users, movies, ratings = load_small_tables()
cat_cols, label_encoders, field_dims, model = load_artifacts_and_model()

# -----------------------------
# 3) ìœ í‹¸
# -----------------------------
def map_single(col, val):
    m = label_encoders[col]
    return m.get(str(val), 0)

def recommend_for_user(original_user_id: int, topn: int = 10):
    """ìœ ì €ê°€ ë³´ì§€ ì•Šì€ ëª¨ë“  ì˜í™”ì— ëŒ€í•´ ì ìˆ˜ ì˜ˆì¸¡ â†’ TopN ë°˜í™˜"""
    # ìœ ì € side features
    urow = users[users["user_id"]==original_user_id]
    if len(urow)==0:
        g, a, o, z = "M", 25, 0, "00000"
    else:
        g, a, o, z = urow.iloc[0][["gender","age","occupation","zip"]]

    # ì´ë¯¸ ë³¸ ì˜í™” ì œì™¸
    seen = set(ratings.loc[ratings["user_id"]==original_user_id, "movie_id"].tolist())
    cand = movies[~movies["movie_id"].isin(seen)].copy()
    if cand.empty:
        return pd.DataFrame(columns=["movie_id","title","genres","score"])

    cand["main_genre"] = cand["genres"].str.split("|").str[0]

    # ë¼ë²¨ ì¸ì½”ë”© (ì—†ëŠ” ê°’ì€ 0ìœ¼ë¡œ)
    mg_idx = cand["main_genre"].astype(str).map(label_encoders["main_genre"]).fillna(0).astype(int).values
    m_idx  = cand["movie_id"].astype(str).map(label_encoders["movie_id"]).fillna(0).astype(int).values

    # ê³ ì • ê°’
    g_idx = map_single("gender", g)
    a_idx = map_single("age", a)
    o_idx = map_single("occupation", o)
    z_idx = map_single("zip", z)

    # ì˜ˆì‹œë¡œ í˜„ì¬ ì—°/ì›”(ë˜ëŠ” ratingsì˜ ì¤‘ì•™ê°’)ì„ ì‚¬ìš©
    year  = int(ratings["rating_year"].median())
    month = int(ratings["rating_month"].median())

    # ì…ë ¥ í–‰ë ¬ (cat_cols ìˆœì„œì™€ ë™ì¼í•´ì•¼ í•¨)
    # ê¸°ë³¸ cat_cols: ["user_id","movie_id","gender","age","occupation","zip","main_genre"]
    n = len(cand)
    U = np.full((n,), map_single("user_id", original_user_id), dtype=np.int32)
    G = np.full((n,), g_idx, dtype=np.int32)
    A = np.full((n,), a_idx, dtype=np.int32)
    O = np.full((n,), o_idx, dtype=np.int32)
    Z = np.full((n,), z_idx, dtype=np.int32)

    # ëª¨ë¸ í•™ìŠµ ì‹œ cat_colsê°€ ìœ„ 7ê°œì™€ ë™ì¼í–ˆë‹¤ê³  ê°€ì •
    X = np.stack([U, m_idx, G, A, O, Z, mg_idx], axis=1)

    scores = model.predict(X, batch_size=65536, verbose=0).ravel()
    cand = cand.assign(score=scores)
    top = cand.sort_values("score", ascending=False).head(topn)
    return top[["movie_id","title","genres","score"]]

def get_user_profile(uid: int, k: int = 10):
    hist = (
        ratings[ratings["user_id"]==uid]
        .sort_values("ts", ascending=False)
        .head(k)
        .merge(movies[["movie_id","title","genres"]], on="movie_id", how="left")
    )
    return hist[["user_id","movie_id","rating","ts","title","genres"]]

# -----------------------------
# 4) UI
# -----------------------------
st.title("ğŸ¬ MovieLens AutoInt ì¶”ì²œ ê²°ê³¼")

col_a, col_b, col_c = st.columns([2,2,1])

with col_a:
    st.subheader("ì‚¬ìš©ì ì„ íƒ")
    uid = st.selectbox(
        "User ID",
        options=sorted(users["user_id"].unique().tolist()),
        index=0
    )
with col_b:
    topn = st.slider("ì¶”ì²œ ê°œìˆ˜", 5, 50, 10, 1)
with col_c:
    st.write("")
    st.write("")

st.divider()

st.markdown("#### ì‚¬ìš©ì ìµœê·¼ ì‹œì²­ ì´ë ¥")
st.dataframe(get_user_profile(uid, k=10), use_container_width=True, height=260)

if st.button("ğŸ” ì¶”ì²œ ê²°ê³¼ ë³´ê¸°", type="primary"):
    with st.spinner("ì¶”ì²œ ê³„ì‚° ì¤‘â€¦"):
        recs = recommend_for_user(int(uid), topn=topn)
    st.markdown("#### ì¶”ì²œ ê²°ê³¼")
    st.dataframe(recs.reset_index(drop=True), use_container_width=True, height=400)
else:
    st.info("ìƒë‹¨ì—ì„œ ì‚¬ìš©ì/ì¶”ì²œ ê°œìˆ˜ë¥¼ ì„¤ì •í•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
